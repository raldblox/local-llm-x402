# local-llm-x402
Expose your local AI model to the internet with usage-based, tokenâ€‘metered inference pricing using x402
